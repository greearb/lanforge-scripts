#!/usr/bin/env python3
# flake8: noqa

"""
NAME: lf_rf_test.py

PURPOSE:
RF Characteristics Test

SETUP:
There need to be a vAP in a Virtual Router  on LANforge , goal is to eventually have autogenerated

EXAMPLE:

./lf_rf_char.py --lf_mgr 192.168.0.104 --lf_port 8080 --lf_user lanforge --lf_passwd lanforge \
    --vap_port 1.1.vap3 --vap_radio 1.1.wiphy3 --vap_channel 36 --vap_antenna all \
    --log_level debug --debug --duration 10s --polling_interval 1s --frame 1400 \
    --frame_interval .01


COPYRIGHT:
    Copyright 2022 Candela Technologies Inc
    License: Free to distribute and modify. LANforge systems must be licensed.

INCLUDE_IN_README
"""

# TODO:  Done, Set report timer on vap and radios to 1 sec, possibly smaller.
# TODO:  Done, Enable extra tx and rx stats on the radios ,

from pprint import pformat
from pprint import pprint
import argparse
import sys
import os
import logging
import importlib
import datetime
import pandas as pd
import json
import traceback
import csv
import time
import re
import platform
import subprocess
import numpy as np

sys.path.append(os.path.join(os.path.abspath(__file__ + "../../../")))
lanforge_api = importlib.import_module("lanforge_client.lanforge_api")
from lanforge_client.lanforge_api import LFSession
from lanforge_client.lanforge_api import LFJsonCommand
from lanforge_client.lanforge_api import LFJsonQuery
from lanforge_client.logg import Logg
LFUtils = importlib.import_module("py-json.LANforge.LFUtils")

lf_json_api = importlib.import_module("py-scripts.lf_json_api")
lf_report = importlib.import_module("py-scripts.lf_report")
lf_graph = importlib.import_module("py-scripts.lf_graph")
lf_bar_graph = lf_graph.lf_bar_graph
lf_bar_line_graph = lf_graph.lf_bar_line_graph
lf_line_graph = lf_graph.lf_line_graph

lf_kpi_csv = importlib.import_module("py-scripts.lf_kpi_csv")
lf_logger_config = importlib.import_module("py-scripts.lf_logger_config")

realm = importlib.import_module("py-json.realm")
Realm = realm.Realm


logger = logging.getLogger(__name__)


if sys.version_info[0] != 3:
    print("This script requires Python 3")
    exit(1)


# RF Characteristics Test
# TODO try to have utilites in own file
class RfCharTest(Realm):
    ANT_STR_TO_INT = {
        "all": 0,
        "1x1": 1,
        "2x2": 4,
        "3x3": 7,
        "4x4": 8,
        "8x8": 9,
    }

    def __init__(self,
                 lf_mgr: str,
                 lf_port: str,
                 lf_user: str,
                 lf_passwd: str,
                 debug: bool,
                 vap_port: str,
                 vap_radio: str,
                 vap_channel: str,
                 vap_antenna: str,
                 vap_txpower: str,
                 vap_bw: str,
                 vap_mode: str,
                 reset_vap: str,
                 polling_interval: str,
                 duration: str,
                 timeout_sec: str,
                 frame: str,
                 frame_interval: str,
                 **kwargs):
        super().__init__(lfclient_host=lf_mgr,
                         lfclient_port=lf_port,
                         debug_=True)
        self.lf_mgr = lf_mgr
        self.lf_port = lf_port
        self.lf_user = lf_user
        self.lf_passwd = lf_passwd
        self.debug = debug

        self.vap_port = self.vap_eid = vap_port  # TODO: Refactor to just vap_port
        self.vap_radio = vap_radio
        self.vap_channel = vap_channel
        self.vap_antenna = RfCharTest.ANT_STR_TO_INT[vap_antenna]
        self.vap_txpower = vap_txpower
        self.vap_bw = vap_bw
        self.vap_mode = LFJsonCommand.AddVapMode[vap_mode].value
        self.reset_vap = reset_vap

        self.polling_interval = polling_interval
        self.duration = duration
        self.timeout_sec = timeout_sec # max seconds to establish the traffic command

        self.frame = frame
        self.frame_interval = frame_interval

        # Get shelf and resource from EIDs
        # Shelf and resource for parent radio and vAP should be the same, so just reference vAP's
        self.shelf, self.resource, self.port_name, *nil = LFUtils.name_to_eid(self.vap_port)
        _, _, self.radio_port_name, *nil = LFUtils.name_to_eid(self.vap_radio)

        self.gen_endpoint = ''
        self.cx_state = ''
        self.bookmark_event_id : int = 0

        # create api_json
        self.json_vap_api = lf_json_api.lf_json_api(lf_mgr=self.lf_mgr,
                                                    lf_port=self.lf_port,
                                                    lf_user=self.lf_user,
                                                    lf_passwd=self.lf_passwd)

        self.json_rad_api = lf_json_api.lf_json_api(lf_mgr=self.lf_mgr,
                                                    lf_port=self.lf_port,
                                                    lf_user=self.lf_user,
                                                    lf_passwd=self.lf_passwd)

        # create a session
        # self.session = LFSession(lfclient_url="http://{lf_mgr}:{lf_port}".format(lf_mgr=self.lf_mgr, lf_port=self.lf_port),
        self.session = LFSession(lfclient_url="http://%s:8080" % self.lf_mgr,
                                 debug=debug,
                                 connection_timeout_sec=4.0,
                                 stream_errors=True,
                                 stream_warnings=True,
                                 require_session=True,
                                 exit_on_error=True)
        if debug:
            Logg.register_method_name("json_post")
            Logg.register_method_name("json_get")
            Logg.register_method_name("get_as_json")
        # type hinting
        self.command: LFJsonCommand
        self.command = self.session.get_command()
        self.query: LFJsonQuery
        self.query = self.session.get_query()

        # get dut information
        self.lf_command = ''
        self.dut_mac = ''
        self.dut_ip = ''
        self.dut_hostname = ''

        # tx data
        self.tx_interval = []
        self.tx_pkts = []
        self.tx_retries = []
        self.tx_failed = []

        # RSSI calculation
        self.rssi_signal = []
        self.rssi_1 = []
        self.rssi_2 = []
        self.rssi_3 = []
        self.rssi_4 = []
        self.rssi_1_count = 0
        self.rssi_2_count = 0
        self.rssi_3_count = 0
        self.rssi_4_count = 0

        # logging
        self.debug = debug


    def remove_generic_cx(self):
        # self.command.die_on_error = False
        # self.exit_on_error = False
        logger.debug("Stopping generic connections")

        generics = self.json_get("/generic/list")
        if generics:
            cx_list = []
            ep_list = []
            noun = 'endpoints'
            if 'endpoints' in generics:
                for item in generics[noun]:
                    k = next(iter(item))
                    if item[k]['name']:
                        if item[k]['name'].startswith("UNKNOWN"):
                            continue
                        cx_list.append("CX_" + item[k]['name'])
                        ep_list.append(item[k]['name'])
                    # else there is no way to stop an un-named endpoint
                    # such an item is a zombie item
            elif 'endpoint' in generics:
                if generics['endpoint']['name'] and not generics['endpoint']['name'].startswith("UNKNOWN"):
                    cx_list.append("CX_" + generics['endpoint']['name'])
                    ep_list.append(generics['endpoint']['name'])
                # else there is no way to stop an un-named endpoint
                # such an item is a zombie item
            if len(cx_list):
                for cx in cx_list:
                    self.command.post_rm_cx(cx_name=cx,
                                            test_mgr='all',
                                            suppress_related_commands=True,
                                            debug=True)
                for ep in ep_list:
                    self.command.post_rm_endp(endp_name=ep,
                                              suppress_related_commands=True,
                                              debug=True)


    def get_recent_lease_events(self):
        """
        Check DHCP lease info from DHCP events.

        Assumes have bookmarked last event by calling `bookmark_events()`
        before calling this function.
        """
        events_rec = self.json_get("/events/since/%d" % self.bookmark_event_id, debug_=self.debug)
        if not events_rec:
            return None
        noun = 'events'
        if noun not in events_rec:
            noun = 'event'
        if noun not in events_rec:
            return None
        dhcp_events = []

        for event_entry in events_rec[noun]:
            event = event_entry[next(iter(event_entry))]
            # pprint(event)
            if event['event description'].startswith("DHCPACK on"):
                dhcp_events.append(event)

        # pprint(["events", dhcp_events])
        return dhcp_events


    def dut_info(self):
        self.json_vap_api.request = 'stations'
        json_stations = []
        sta_ap = ''
        dut_ip = ''
        dut_mac = ''
        dut_hostname = ''

        self.shelf, self.resource, self.port_name, *nil = LFUtils.name_to_eid(self.vap_port)
        self.vap_eid = "%s.%s.%s" % (self.shelf, self.resource, self.port_name)

        event_recs = self.get_recent_lease_events()
        other_findings : dict = {}
        # look for event containing the vap_name then get the station IP from events

        logger.info(f"Gathering station DUT info from vAP \'{self.port_name}\' events")
        logger.debug(f"Inspecting {len(event_recs)} Events for vAP \'{self.port_name}\'")
        for record in event_recs:
            if not (('event description' in record) or record['event description']):
                continue

            hunks : list[str] = record['event description'].split(" ")
            if hunks[6] != self.port_name:
                if hunks[6] not in other_findings:
                    other_findings[hunks[6]] = []
                other_findings[hunks[6]].append(hunks[4])
                continue

            if not self.dut_mac:
                self.dut_mac = hunks[4]

            dut_ip = hunks[2]
            self.dut_ip = dut_ip
            logger.warning("==  ==  ==  ==  Found DUT IP: %s ==  ==  ==  ==  " % dut_ip)
            break

        if not self.dut_ip:
            for vap in other_findings.keys():
                logger.info("  ...%s has: %s" % (vap, ", ".join(other_findings[vap])))

        try:
            # does not need specific port information
            snc = subprocess.Popen("sync")
            snc.wait()
            if not self.vap_eid:
                self.vap_eid = "1.%s.%s" % (self.resource, self.port_name)
            self.command.post_probe_port(shelf=1,
                                         resource=self.resource,
                                         port=self.port_name,
                                         key='probe_port.quiet.' + self.vap_eid)
            time.sleep(0.5)
            json_stations, *nil = self.json_vap_api.get_request_stations_information()
            self.dut_mac = json_stations['station']['station bssid']
            sta_ap = json_stations['station']['ap']
            logger.debug("Station DUT associated to BSSID: {mac}".format(mac=self.dut_mac))
        except BaseException:
            # Maybe we have multiple stations showing up on multiple VAPs...find the first one that matches our vap.
            logger.debug(f"Searching for vAP \'{self.vap_eid}\' in station DUT association info")
            try:
                pronoun = 'stations'
                if pronoun not in json_stations:
                    pronoun = 'station'
                if pronoun not in json_stations:
                    logger.info("Did not find station DUT, trying again")
                    return False

                for s in json_stations[pronoun]:
                    keys = list(s.keys())
                    vals = s[keys[0]]

                    if vals['ap'] == self.vap_eid:
                        sta_ap = self.vap_eid
                        self.dut_mac = vals['station bssid']
                        logger.warning(" Found sta, ap: %s  mac: %s" % (sta_ap, self.dut_mac))
                        break
            except BaseException:
                logger.info("waiting on stations")
                pass

            if sta_ap == "":
                logger.info("  No stations using vAP [%s]" % self.vap_eid)
                station_macs : list[str] = []
                for record in json_stations['stations']:
                    bss = next(iter(record))
                    station_macs.append(bss[bss.rindex('.')+1:])
                logger.info("   stations seen: "+", ".join(station_macs))
                #logger.warning(pformat(json_stations))
                return False

        # Make sure the station is on correct IP vap
        if (sta_ap != self.vap_eid):
            logger.warning(f"Detected station DUT associated to AP \'{sta_ap}\', expected it to be associated to vAP DUT \'{self.vap_eid}\'")
            return False

        if not dut_ip:
            # get the IP from port probe
            logger.warning("Station DUT IP not found in event records, checking port probe instead")
            self.lf_command = ["../lf_portmod.pl", "--manager", self.lf_mgr, "--card", str(self.resource), "--port_name", self.port_name,
                               "--cli_cmd", "probe_port 1 {resource} {port}".format(resource=self.resource, port=self.port_name)]
            logger.debug("command: {cmd}".format(cmd=self.lf_command))
            summary_output = ''
            process_begin_ms = now_millis()
            summary = subprocess.Popen(self.lf_command, universal_newlines=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)

            for line in iter(summary.stdout.readline, ''):
                logger.debug(line)
                summary_output += line
                # sys.stdout.flush() # please see comments regarding the necessity of this line
            summary.wait()
            process_end_ms = now_millis()
            logger.debug("lfportmod took %d ms" % (process_end_ms - process_begin_ms))
            logger.debug(summary_output)  # .decode('utf-8', 'ignore'))

            search_dhcp_lease = False
            search_equals = False
            for line in summary_output.splitlines():
                if (line.startswith("DHCPD-Lease-File-Contents")):
                    search_equals = True
                    continue

                if (search_equals and line.startswith("=========")):
                    search_dhcp_lease = True
                    continue

                if (search_dhcp_lease):
                    pat = "(\\S+)\\s+(\\S+)\\s+(\\S+)"
                    m = re.search(pat, line)
                    if (m is not None):
                        dut_mac = m.group(1)
                        dut_ip = m.group(2)
                        dut_hostname = m.group(3)
                    else:
                        pat = "(\\S+)\\s+(\\S+)"
                        m = re.search(pat, line)
                        if (m is not None):
                            dut_mac = m.group(1)
                            dut_ip = m.group(2)
                # there should only be one connection

            logger.debug(f"Port probe MAC: {dut_mac}, IP: {dut_ip}")
            if dut_mac != self.dut_mac:
                logger.error(f"Port probe MAC mismatch. Expected {self.dut_mac}, found {dut_mac}")
                return False
            self.dut_ip = dut_ip
            #self.dut_hostname = dut_hostname

        logger.info(f"Found station DUT with MAC {self.dut_mac} and IPv4 address {self.dut_ip}")
        return True

    def clear_dhcp_lease(self):
        logger.info(f"Clearing vAP DUT \'{self.vap_port}\' DHCP leases")

        extra = 'dhcp_leases'
        self.command.post_clear_port_counters(shelf=self.shelf,
                                              resource=self.resource,
                                              port=self.port_name,
                                              extra=extra)

    def clear_port_counters(self):
        logger.info(f"Clearing port counters for vAP DUT \'{self.vap_port}\' and parent radio \'{self.vap_radio}\'")

        self.shelf, self.resource, self.port_name, *nil = LFUtils.name_to_eid(self.vap_port)
        # may have to add extra to
        self.command.post_clear_port_counters(shelf=self.shelf,
                                              resource=self.resource,
                                              port=self.port_name,
                                              extra=None)

        # Clear radio stats too
        self.shelf, self.resource, self.port_name, *nil = LFUtils.name_to_eid(self.vap_radio)
        self.command.post_clear_port_counters(shelf=self.shelf,
                                              resource=self.resource,
                                              port=self.port_name,
                                              extra=None)
    # ./lf_generic_ping.pl --mgr 192.168.0.104 --resource 1 --dest 10.10.10.4 -i vap3 --cmd 'lfping -s 1400 -i 0.01 -I vap3 10.10.10.4

    # set_port 1 1 vap3 NA NA NA NA NA NA NA NA NA 32768 5000 NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
    # set_port 1 1 vap3 NA NA NA NA NA NA NA NA NA 32768 1000
    def set_port_report_timer(self, port, milliseconds=1000):
        self.command.post_set_port(shelf=self.shelf,
                                   resource=self.resource,
                                   port=self.port_name,
                                   interest=32768,
                                   report_timer=int(milliseconds),
                                   debug=self.debug)

    # enable extra_rxstatus extra_txstatus
    def set_wifi_radio(self, flags_list=[]):
        flag_val = 0
        # flag_val = LFPost.set_flags(SetWifiRadioFlags0, flag_names=['extra_rxstatus', 'extra_tx_status'])
        flag_val = self.command.set_flags(self.command.SetWifiRadioFlags, flag_val, flag_names=flags_list)

        self.command.post_set_wifi_radio(shelf=self.shelf,
                                         resource=self.resource,
                                         radio=self.radio_port_name,
                                         flags=flag_val,
                                         flags_mask=flag_val,
                                         # do not adjust radio mode
                                         debug=self.debug)

    def generic_ping(self):
        self.shelf, self.resource, self.port_name, *nil = LFUtils.name_to_eid(self.vap_port)
        self.gen_endpoint = "CX_lfping_{port_name}".format(port_name=self.port_name)

        # need to change the current working director to run lf_generic_ping.pl
        cwd_orig = os.getcwd()
        logger.info("Current Working Directory is :{cwd}".format(cwd=cwd_orig))
        os.chdir('../')
        cwd_new = os.getcwd()
        logger.info("Move up one dir Working Directory is :{cwd}".format(cwd=cwd_new))

        self.lf_command = ["./lf_generic_ping.pl", "--mgr", self.lf_mgr, "--resource", str(self.resource), "--dest", self.dut_ip,
                           "-i", self.port_name, "--cmd", 'lfping -s {frame} -i {frame_interval} -I {port_name} {dut_ip}'.
                           format(frame=self.frame, frame_interval=self.frame_interval, port_name=self.port_name, dut_ip=self.dut_ip)]
        logger.debug("lf_generic_ping.pl : {cmd}".format(cmd=self.lf_command))
        summary_output = ''

        summary = subprocess.Popen(self.lf_command, universal_newlines=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)

        for line in iter(summary.stdout.readline, ''):
            logger.debug(line)
            summary_output += line
            # sys.stdout.flush() # please see comments regarding the necessity of this line
        summary.wait()
        logger.debug(summary_output)  # .decode('utf-8', 'ignore'))
        os.chdir(cwd_orig)
        cwd_final = os.getcwd()
        logger.info("Current Working Directory is :{cwd}".format(cwd=cwd_final))

    # for updating the ping information
    # ./lf_generic_ping.pl --mgr 192.168.0.104 --resource 1 --dest 10.10.10.4 -i vap3 --cmd 'lfping -s 1400 -i 0.01 -I vap3 10.10.10.4'
    # add_gen_endp

    # TODO not working yet using perl command
    # TODO pass port
    def add_gen_endp(self):
        self.shelf, self.resource, self.port_name, *nil = LFUtils.name_to_eid(self.vap_port)
        # cross connects prepend CX
        self.gen_endpoint = "CX_lfping_{port_name}".format(port_name=self.port_name)
        self.command.post_add_gen_endp(
            alias=self.gen_endpoint,
            port=self.port_name,
            resource=self.resource,
            shelf=self.shelf,
            p_type='gen_generic',   # gen_generic is default
            debug=self.debug
        )

    # TODO not working yet using perl command
    # TODO pass port
    # set_gen_cmd
    def set_gen_cmd(self):
        self.shelf, self.resource, self.port_name, *nil = LFUtils.name_to_eid(self.vap_port)
        lf_command = "lfping '-s {frame} -i {frame_interval} -I {port_name} {ip}".format(
            frame=self.frame, frame_interval=self.frame_interval, port_name=self.port_name, ip=self.dut_ip)
        self.command.post_set_gen_cmd(
            command=lf_command,
            name=self.gen_endpoint,
            debug=self.debug)
        self.wait_until_endps(base_url=self.lfclient_url,
                              endp_list=("lf_ping_%s" % self.vap_port),
                              debug=False,
                              timeout=10)


    def set_cx_state(self):
        self.command.post_set_cx_state(cx_name=self.gen_endpoint,
                                       cx_state=self.cx_state,
                                       test_mgr='all',
                                       debug=self.debug)

    def bookmark_events(self):
        self.bookmark_event_id = 0
        events_rec = self.json_get("/events/last/1", debug_=self.debug)
        if events_rec:
            noun = "events"
            if noun not in events_rec:
                noun = "event"
            if noun in events_rec:
                # pprint(events_rec[noun])
                self.bookmark_event_id = int(events_rec[noun]["id"])



    def configure_vap(self):
        """Configure vAP including mode, channel, channel width, txpower."""
        # Set vAP transmit power. This should already be validated in argument validation step.
        # Transmit power can be any integer between -1 and 30, inclusive
        if self.vap_txpower == "DEFAULT":
            tx_pow = -1
        else:
            txpower_int_str = self.vap_txpower.strip("dBm")
            tx_pow = int(txpower_int_str)

        self.command.post_set_wifi_radio(shelf=self.shelf,
                                         resource=self.resource,
                                         radio=self.port_name,
                                         antenna=self.vap_antenna,
                                         channel=self.vap_channel,
                                         txpower=tx_pow,
                                         # do not set radio mode here
                                         debug=self.debug)

        vap_flags = "NA"
        vap_flagmask = "NA"
        t_channel : int = 0
        t_band : int = 0

        if "e" in self.vap_channel:
            # we are 6Ghz
            t_channel = int( self.vap_channel[0:-1])
            logger.warning("6gz channel is {}".format(t_channel))
            if (t_channel >= 1) and (t_channel <= 233):
                t_band=6
        else:
            t_channel = int(self.vap_channel)
            if (t_channel >= 1) and (t_channel <= 15):
                t_band=2
            elif (t_channel >= 32) and (t_channel <= 177):
                t_band=5
            elif (t_channel >= 191):
                t_band=6
        if t_channel == 0:
            raise Exception("strange channel: {}".format(self.vap_channel))
        if t_band < 2:
            raise Exception("strange bandwidth: {}".format(t_band))

        default_flags_24g = self.command.AddVapFlags.use_bss_load \
            | self.command.AddVapFlags.use_bss_transition \
            | self.command.AddVapFlags.use_rrm_report
        default_flags_5g = self.command.AddVapFlags.enable_80211d \
            | self.command.AddVapFlags.p_80211h_enable \
            | self.command.AddVapFlags.use_bss_load \
            | self.command.AddVapFlags.use_bss_transition \
            | self.command.AddVapFlags.use_rrm_report
        default_flags_6g = self.command.AddVapFlags.use_bss_load \
            | self.command.AddVapFlags.use_bss_transition \
            | self.command.AddVapFlags.use_rrm_report
        t_flags: int = -1
        t_flagmask: int = self.command.AddVapFlags.disable_ht40 \
                            | self.command.AddVapFlags.disable_ht80 \
                            | self.command.AddVapFlags.ht160_enable
        if t_band == 6:
            # have to specify hostapd_config in flags to make sure that custom config
            # checkbox gets turned off
            t_flagmask |= self.command.AddVapFlags.hostapd_config
        if self.vap_bw and (not t_band or self.vap_bw == "NA"):
            # logger.error("unable to set bandwidth without knowing channel")
            raise Exception("unable to set bandwidth without knowing channel")
        if self.vap_bw:
            if t_band == 2:
                t_flags = default_flags_24g
                t_flagmask |= default_flags_24g
            elif t_band == 5:
                t_flags = default_flags_5g
                t_flagmask |= default_flags_5g
            elif t_band == 6:
                t_flags = default_flags_6g
                t_flagmask |= default_flags_6g
            else:
                raise ValueError("Unknown band %s" % t_band)

            if self.vap_bw == "20":
                t_flags |= self.command.AddVapFlags.disable_ht40
                    # disabling ht80 appears to remove usefulness of disable_ht40
                    # | self.command.AddVapFlags.disable_ht80
            if self.vap_bw == "40":
                t_flags |= self.command.AddVapFlags.disable_ht80
            if self.vap_bw == "80":
                # disabling ht40 implies forcing 20Mhz
                # t_flags |= self.command.AddVapFlags.disable_ht40
                if t_band == 2:
                    raise ValueError("80 mhz bandwidth only available within 5ghz and 6gz frequencies")
            if self.vap_bw == "160":
                if t_band == 2:
                    raise ValueError("80 mhz bandwidth only available within 5ghz and 6gz frequencies")
                if t_band == 5 and not (t_channel in (36, 100)):
                    raise ValueError("160 mhz bandwidth only available within 5ghz channels 36 and 100")
                t_flags |= self.command.AddVapFlags.ht160_enable

        if t_flags > -1:
            vap_flags = str(hex(t_flags))
            vap_flagmask = str(hex(t_flagmask))
        else:
            logger.warning("t_flags does not look right: %s" % t_flags)
            time.sleep(5)

        v_name = self.vap_port
        if self.vap_port.find('.') > -1:
            v_name = self.vap_port[self.vap_port.rindex('.')+1:]
        r_name = self.vap_radio
        if self.vap_radio.find('.') > -1:
            r_name = self.vap_radio[self.vap_radio.rindex('.')+1:]

        logger.debug("configure_vap: vap_mode            [{}]".format(self.vap_mode))
        logger.debug("configure_vap: vap_radio           [{}]".format(self.vap_radio))
        logger.debug("configure_vap: vap_port            [{}]".format(self.vap_port))
        logger.debug("configure_vap: port_name           [{}]".format(self.port_name))
        logger.debug("configure_vap: vap_channel         [{}]".format(self.vap_channel))
        logger.debug("configure_vap: vap_bw              [{}]".format(self.vap_bw))
        logger.debug("configure_vap: vap_flags           [{}]".format(vap_flags))
        logger.debug("configure_vap: vap_flagmask        [{}]".format(vap_flagmask))

        self.command.post_add_vap(shelf=1,
                                  resource=self.resource,
                                  radio=r_name,
                                  ap_name=v_name,
                                  mode=self.vap_mode,
                                  flags=vap_flags,
                                  flags_mask=vap_flagmask,
                                  debug=True)
        queried_mode = "none"
        e_w : list = []
        poll_start_sec = lanforge_api._now_sec()
        deadline_sec = poll_start_sec + 16
        while (queried_mode == "none") and (deadline_sec > lanforge_api._now_sec()):
            response = self.query.get_port(eid_list=["1.1.vap0000"],
                                           requested_col_names=["alias", "mode"],
                                           errors_warnings=e_w,
                                           debug=True)
            if not response:
                logger.error("No response to query get_port()")
            else:
                logger.debug(" Response: %s"        % pformat(response))
            if e_w:
                logger.warning("get_port warnings: %s" % pformat(e_w))
            if "mode" in response:
                queried_mode = response["mode"]
            else:
                logger.warning("get_port did not provide vap[mode]")

        logger.debug("done polling for vap mode")

        if self.reset_vap:
            logger.warning("resetting vap [{}]".format(self.port_name))
            self.command.post_reset_port(shelf=self.shelf,
                                         resource=self.resource,
                                         port=self.port_name)
        # Port reset can make everything kinda hang in limbo
        # because we wait for report_timer seconds for ports to report
        # again. Lets prompt the port and the virtual router to
        # refresh to help get our dhcp leases visible as soon as possible
        time.sleep(1)
        ncsp_flags : int = LFJsonCommand.NcShowPortsProbeFlags.WIFI \
                            | LFJsonCommand.NcShowPortsProbeFlags.MII \
                            | LFJsonCommand.NcShowPortsProbeFlags.BRIDGE \
                            | LFJsonCommand.NcShowPortsProbeFlags.GW
        self.command.post_nc_show_ports(shelf=1,
                                        resource=self.resource,
                                        port=self.port_name,
                                        probe_flags=ncsp_flags)
        LFUtils.wait_until_ports_admin_up(base_url=self.lfclient_url,
                                          resource_id=self.resource,
                                          port_list=[self.port_name])
        self.command.post_show_vr(shelf=1, resource=self.resource, router='all')
        self.command.post_show_vrcx(shelf=1, resource=self.resource, cx_name='all')


    def verify_dut_stations(self, deadline_millis: int, dhcp_lookup_ms: int, max_dhcp_lookups: int):
        """
        Verify that there exists one or more station DUTs with DHCP leases from the vAP DUT.
        This method will reset the vAP if necessary.
        """
        begin_lease_lookup_ms = now_millis()
        last_vap_reset = now_millis()
        try_count = int(max_dhcp_lookups)
        found_station : bool = False

        # Iterate for defined number of tries, counting down 'try_count' until we find
        # stations with DHCP leases corresponding to this vAP
        while try_count > 0:
            if self.dut_info():
                found_station = True
                break

            attempt_num = 1 + max_dhcp_lookups - try_count
            logger.info(f"Looking for DUT info from vAP DUT data, attempt {attempt_num}/{max_dhcp_lookups}")

            if now_millis() >= deadline_millis:
                raise ValueError("Time expired for DHCP lease lookups")

            # Request non-cached vAP port update from server
            self.command.post_nc_show_ports(shelf=1,
                                            resource=self.resource,
                                            port=self.port_name,
                                            probe_flags=(LFJsonCommand.NcShowPortsProbeFlags.WIFI \
                                                            | LFJsonCommand.NcShowPortsProbeFlags.MII \
                                                            | LFJsonCommand.NcShowPortsProbeFlags.ETHTOOL \
                                                            | LFJsonCommand.NcShowPortsProbeFlags.EASY_IP_INFO),
                                            debug=self.debug)
            # rf_char.command.post_show_vr(shelf=1, resource=rf_char.resource, router='all', debug=rf_char.debug)

            self.command.post_probe_port(shelf=1,
                                         resource=self.resource,
                                         port=self.port_name,
                                         key='probe_port.quiet.' + self.vap_eid)
            time.sleep(dhcp_lookup_ms/1000)
            try_count -= 1

            # A vAP can take about 15 seconds to acquire a lease, hopefully 10.
            # Do not reset a vAP sooner than that or it just takes longer.
            if now_millis() > (last_vap_reset + 16000):
                v_name = self.vap_port
                logger.warning(f"Resetting vAP port {v_name}")

                if v_name.find('.') > -1:
                    v_name = self.vap_port[ self.vap_port.rindex('.')+1 :]

                self.command.post_reset_port(shelf=1,
                                             resource=self.resource,
                                             port=v_name)

                LFUtils.wait_until_ports_admin_up(base_url=self.lfclient_url,
                                                  resource_id=self.resource,
                                                  port_list=[self.port_name])
                last_vap_reset = now_millis()

        if found_station:
            lease_lookup_time = float((now_millis() - begin_lease_lookup_ms) / 1000.0)
            logger.info(f"Station DUT DHCP lease lookup time took {lease_lookup_time} sec")
        else:
            logger.error(f"Unable to find station DUT with DHCP lease after {max_dhcp_lookups} inspections of DHCP table")
            sys.exit(1)

        if now_millis() >= deadline_millis:
            raise ValueError("time expired for DHCP lease lookups")

    def start(self):
        # first read with
        self.json_vap_api.port = self.vap_port
        self.json_vap_api.update_port_info()
        self.json_vap_api.csv_mode = 'write'
        self.json_vap_api.update_csv_mode()
        self.json_vap_api.request = 'port'

        self.json_rad_api.port = self.vap_radio
        self.json_rad_api.update_port_info()
        self.json_rad_api.csv_mode = 'write'
        self.json_rad_api.update_csv_mode()
        self.json_rad_api.request = 'port'

        self.tx_interval = []
        self.tx_interval_time = []
        self.tx_pkts = []
        self.tx_retries = []
        self.tx_failed = []
        self.tx_rate = []
        self.rx_rate = []

        self.rssi_signal = []
        self.rssi_1 = []
        self.rssi_2 = []
        self.rssi_3 = []
        self.rssi_4 = []
        self.rssi_1_count = 0
        self.rssi_2_count = 0
        self.rssi_3_count = 0
        self.rssi_4_count = 0

        # create lfping generic
        '''
        # Using lanforge_api
        logger.info("create generic endpoint")
        self.add_gen_endp()
        logger.info("set frame {frame} frame_interval {interval}".format(frame=self.frame,interval=self.frame_interval))
        self.set_gen_cmd()
        '''
        # use the lf_generic_ping.pl
        self.generic_ping()
        logger.info("start the lfping cx traffic frame: {frame} frame_interval: {frame_interval}".format(frame=self.frame, frame_interval=self.frame_interval))
        # TODO understand when data is read
        # This needs to be removed
        time.sleep(1)

        self.cx_state = 'RUNNING'  # RUNNING< SWITCHB, QUIESCE, STOPPED, or DELETED
        self.set_cx_state()

        logger.info("clear port counters")
        self.clear_port_counters()

        jason_vap_port_stats, *nil = self.json_vap_api.get_request_port_information(port=self.vap_port)
        if not jason_vap_port_stats:
            raise ValueError("json_vap_api.get_request_port_information returned nothing")

        tx_pkts_previous = 0
        tx_retries_previous = 0

        self.json_vap_api.csv_mode = 'append'
        self.json_vap_api.update_csv_mode()

        cur_time = datetime.datetime.now()
        end_time = self.parse_time(self.duration) + cur_time
        polling_interval_milliseconds = self.duration_time_to_milliseconds(self.polling_interval)
        sleep_interval = (polling_interval_milliseconds/1000)/2
        interval = 0
        # initialize time stamps
        json_vap_port_stats, *nil = self.json_vap_api.get_request_port_information(port=self.vap_port)
        current_time_stamp = json_vap_port_stats["interface"]["time-stamp"]
        previous_time_stamp = current_time_stamp
        tx_pkts_previous = json_vap_port_stats["interface"]["tx pkts"]
        tx_retries_previous = json_vap_port_stats["interface"]["wifi retries"]
        while cur_time < end_time:
            interval_time = cur_time + datetime.timedelta(milliseconds=polling_interval_milliseconds)

            # check the port time stamp to see if data changed
            # check 1/2 polling interval
            while cur_time < interval_time:
                cur_time = datetime.datetime.now()
                # read the current time
                time.sleep(sleep_interval)
                json_vap_port_stats, *nil = self.json_vap_api.get_request_port_information(port=self.vap_port)
                current_time_stamp = json_vap_port_stats["interface"]["time-stamp"]
                if current_time_stamp != previous_time_stamp:
                    logger.debug("new TX stats: time_stamp {time} previous_time_stamp {pre_time}".format(time=current_time_stamp, pre_time=previous_time_stamp))
                    previous_time_stamp = current_time_stamp
                    break
                # Here check if the time stamp has changed

            # json_vap_port_stats, *nil = self.json_vap_api.get_request_port_information(port=self.vap_port)
            interval += float(polling_interval_milliseconds) / 1000
            self.tx_interval.append(round(interval, 2))
            current_time = current_time_stamp.split()
            self.tx_interval_time.append(current_time[1])

            if tx_pkts_previous <= json_vap_port_stats["interface"]["tx pkts"]:
                self.tx_pkts.append(json_vap_port_stats["interface"]["tx pkts"] - tx_pkts_previous)
            else:
                self.tx_pkts.append(0)
            tx_pkts_previous = json_vap_port_stats["interface"]["tx pkts"]

            if tx_retries_previous <= json_vap_port_stats["interface"]["wifi retries"]:
                self.tx_retries.append(json_vap_port_stats["interface"]["wifi retries"] - tx_retries_previous)
            else:
                self.tx_retries.append(0)
            tx_retries_previous = json_vap_port_stats["interface"]["wifi retries"]

            self.tx_failed.append(round(json_vap_port_stats["interface"]["tx-failed %"], 2))
            self.rx_rate.append(json_vap_port_stats["interface"]["rx-rate"])
            self.tx_rate.append(json_vap_port_stats["interface"]["tx-rate"])
            # calculated the transmitted packets compared to number of retries

            # take samples of RSSI
            self.json_vap_api.request = 'stations'
            # port not needed for all
            json_stations, *nil = self.json_vap_api.get_request_stations_information()
            logger.info("json_stations {json}".format(json=pformat(json_stations)))
            chain_rssi : list = []
            if "station" in json_stations:
                self.rssi_signal.append(json_stations['station']['signal'])
                chain_rssi_str = json_stations['station']['chain rssi']
                chain_rssi = chain_rssi_str.split(',')
            elif "stations" in json_stations:
                # Maybe we have multiple stations showing up on multiple VAPs...find the first one that matches our vap.
                # pprint(json_stations)
                # This should give us faster lookup if I knew how to use it.
                # sta_key = "0.0.0.%s"%(self.dut_mac)
                #pprint("key: %s"%(sta_key))
                for s in json_stations['stations']:
                    keys = list(s.keys())
                    vals = s[keys[0]]
                    if vals['station bssid'] == self.dut_mac:
                        self.rssi_signal.append(int(vals['signal'].lstrip()))
                        chain_rssi_str = vals['chain rssi']
                        chain_rssi = chain_rssi_str.split(',')
                        break
            else:
                logger.info("json_stations lacks station info, next...")
                continue

            if chain_rssi:
                logger.info("RSSI chain length {chain}".format(chain=len(chain_rssi)))
                if len(chain_rssi) == 1:
                    self.rssi_1.append(int(chain_rssi[0].lstrip()))
                    self.rssi_2.append(np.nan)
                    self.rssi_3.append(np.nan)
                    self.rssi_4.append(np.nan)
                    self.rssi_1_count = self.rssi_1_count + 1
                elif len(chain_rssi) == 2:
                    self.rssi_1.append(int(chain_rssi[0].lstrip()))
                    self.rssi_2.append(int(chain_rssi[1].lstrip()))
                    self.rssi_3.append(np.nan)
                    self.rssi_4.append(np.nan)
                    self.rssi_2_count = self.rssi_2_count + 1
                elif len(chain_rssi) == 3:
                    self.rssi_1.append(int(chain_rssi[0].lstrip()))
                    self.rssi_2.append(int(chain_rssi[1].lstrip()))
                    self.rssi_3.append(int(chain_rssi[2].lstrip()))
                    self.rssi_4.append(np.nan)
                    self.rssi_3_count = self.rssi_3_count + 1
                elif len(chain_rssi) == 4:
                    self.rssi_1.append(int(chain_rssi[0].lstrip()))
                    self.rssi_2.append(int(chain_rssi[1].lstrip()))
                    self.rssi_3.append(int(chain_rssi[2].lstrip()))
                    self.rssi_4.append(int(chain_rssi[3].lstrip()))
                    self.rssi_4_count = self.rssi_4_count + 1
                else:
                    self.rssi_1.append(np.nan)
                    self.rssi_2.append(np.nan)
                    self.rssi_3.append(np.nan)
                    self.rssi_4.append(np.nan)
                    self.rssi_4_count = 0

        self.json_vap_api.csv_mode = 'write'
        self.json_vap_api.update_csv_mode()

        # TODO make the get_request more generic just set the request
        self.json_rad_api.request = 'wifi-stats'
        # Read the vap device stats, it will also be able to report underlying radio stats as needed.
        request_attempts : int = 6
        json_wifi_stats : dict = None
        while request_attempts >= 0:
            request_attempts -= 1
            json_wifi_stats, *nil = self.json_rad_api.get_request_wifi_stats_information(port=self.vap_port)
            if not json_wifi_stats:
                raise ValueError("__name__ get_request_wifi_stats_information unable to create json_wifi_stats")
            if self.port_name not in json_wifi_stats:
                # raise ValueError("port %s not in json_wifi_stats" % self.port_name)
                time.sleep(1)
                continue
            request_attempts = -1

        logger.debug("wifi-stats output, vap-radio: %s radio port name %s:"%(self.vap_radio, self.port_name))
        # pprint(json_wifi_stats)

        # Stop Traffic
        self.cx_state = 'STOPPED'  # RUNNING< SWITCHB, QUIESCE, STOPPED, or DELETED
        self.set_cx_state()

        return jason_vap_port_stats, json_wifi_stats

        # gather interval samples read stations to get RX Bytes, TX Bytes, TX Retries,

        # read the extended mgr tab to get rx tx MCS, NSS

    def read_wifi_stats(self):
        pass

    def read_stations(self):
        pass


# sort the values when in a list
def num_sort(strn):
    # getting number using isdigit() and split()
    computed_num = [ele for ele in strn[0].split('_') if ele.isdigit()]
    # assigning lowest weightage to strings
    # with no numbers
    if len(computed_num) > 0:
        return int(computed_num[0])
    return -1

def length_sort(strn):
    return len(strn[0])


def now_millis() -> int:
    return round(time.time() * 1000)


def parse_args():
    parser = argparse.ArgumentParser(
        prog='lf_rf_char.py',
        formatter_class=argparse.RawTextHelpFormatter,
        epilog='''\
            lf_rf_char.py : RF Characteristics test
            ''',
        description='''\
Summary :
---------
Gather Tx and Rx RF Characteristic for a specific duration and polling interval

Example :
---------
./lf_rf_char.py \
    --lf_mgr            192.168.0.104 \
    --vap_port          1.1.vap3 \
    --vap_radio         1.1.wiphy3 \
    --vap_channel       36 \
    --vap_antenna       0 \
    --duration          10s \
    --polling_interval  1s \
    --frame             1400 \
    --frame_interval    .01

for individual command telnet <lf_mgr> 4001 ,  then can execute cli commands
            ''')
    # LANforge configuration
    parser.add_argument("--mgr", "--lf_mgr",
                        dest="lf_mgr",
                        help="address of the LANforge GUI machine (localhost is default)",
                        type=str,
                        default='localhost')
    parser.add_argument("--mgr_port", "--lf_port",
                        dest="lf_port",
                        help="IP Port the LANforge GUI is listening on (8080 is default)",
                        default=8080)
    parser.add_argument("--lf_user",
                        help="user: lanforge",
                        type=str,
                        default='lanforge')
    parser.add_argument("--lf_passwd",
                        help="passwd: lanforge",
                        type=str,
                        default='lanforge')

    # vAP Configuration
    parser.add_argument("--vap_port",
                        help="port: 1.1.vap3  provide full eid (endpoint id)",
                        type=str,
                        required=True)
    parser.add_argument("--vap_radio",
                        help="--vap_radio wiphy0",
                        type=str,
                        required=True)
    parser.add_argument('--vap_bw',
                        help="Specify the bandwidth for the vAP. "
                             "Not all bandwidth settings are available for all radios.",
                        choices={"20", "40", "80", "160"},
                        required=True)
    parser.add_argument("--vap_channel",
                        help="Specify the channel of the radio e.g. 6 (2.4G), 36 (5G), 1e (6G) "
                             "Please append 'e' for all 6Ghz channels. "
                             "This parameter is required to use --vap_bw parammeter.",
                        type=str,
                        required=True)
    parser.add_argument("--vap_antenna",
                        help="Spatial stream configuration of vAP. Support for each configuration depends on the radio used.",
                        type=str,
                        choices={"all", "1x1", "2x2", "3x3", "4x4", "8x8"},
                        default="all")
    parser.add_argument("--vap_mode",
                        help="WiFi modes defined by www.candelatech.com/lfcli_ug.php#add_vap "
                             "Includes 802.11a, a, b, g, abg, abgn, bgn, bg, abgnAC, anAC, an, bgnAC, abgnAX, bgnAX, anAX, aAX",
                        default="AUTO")
    parser.add_argument('--vap_txpower',
                        help="Transmit power used by vAP radio measured in dBm, e.g. \'25dBm\'"
                             "Accepted values are \'DEFAULT\' or an integer between -1 to 30, inclusive.",
                        type=str,
                        default="DEFAULT")
    parser.add_argument('--reset_vap', action='store_true',
                        help="Specify this if DHCP leases do not disappear from the vAP. "
                             "Default behavior is to not reset the vAP")

    # Reporting Configuration
    parser.add_argument('--local_lf_report_dir',
                        help="--local_lf_report_dir override the report path, primary use when running test in test suite. "
                             "The lowest actual directory will be <local_lf_report_dir>/<time-date>_rf_characteristics/ "
                             "If you specify final_report_dir, that directory will be moved the the <final_report_dir> directory",
                        default="")
    parser.add_argument('--final_report_dir',
                        help="moves the default report directory (mv <time-date>_rf_characteristics) to new name. "
                             "If this is not a full qualified path, it will default to /home/lanforge/html-reports/<final_report_dir>")
    parser.add_argument('--no_pdf',
                        help="specify this to skip PDF generation",
                        action='store_true')
    parser.add_argument('--no_html',
                        help="specify this to skip generating a HTML report and charts, only csv output would be created. "
                             "Implies --no_pdf as HTML report is basis for PDF report",
                        action='store_true')
    parser.add_argument("--test_rig",
                        help="test rig for kpi.csv, testbed that the tests are run on",
                        default="lanforge")
    parser.add_argument("--test_tag",
                        help="test tag for kpi.csv, test specific information to differenciate the test",
                        default="kpi_generation")
    parser.add_argument("--dut_hw_version",
                        help="dut hw version for kpi.csv, hardware version of the device under test",
                        default="")
    parser.add_argument("--dut_sw_version",
                        help="dut sw version for kpi.csv, software version of the device under test",
                        default="")
    parser.add_argument("--dut_model_num", "--dut_model_no",
                        dest="dut_model_num",
                        help="dut model for kpi.csv,  model number / name of the device under test",
                        default="")
    parser.add_argument("--dut_serial_num", "--dut_serial_no",
                        dest="dut_serial_num",
                        help="dut serial num for kpi.csv,  model serial number ",
                        default="")
    parser.add_argument("--test_priority",
                        help="dut model for kpi.csv, test-priority is arbitrary number",
                        default="95")
    parser.add_argument("--test_id",
                        help="test-id for kpi.csv,  script or test name",
                        default="kpi_unit_test")
    parser.add_argument("--csv_outfile",
                        help="csv outfile",
                        default="lf_rf_char")

    # Logging Configuration
    parser.add_argument('--log_level',
                        default=None,
                        help='Set logging level: debug | info | warning | error | critical')
    parser.add_argument("--lf_logger_config_json",
                        help="--lf_logger_config_json <json file> , json configuration of logger")
    parser.add_argument('--debug',
                        help='Legacy debug flag',
                        action='store_true')

    # Test Configuration
    parser.add_argument('--desc',
                        help="--desc <test description> , if not provided will section not printed")
    parser.add_argument('--polynomial',
                        help="--polynomial store_true , show polynomial lines on retries graph",
                        action="store_true")
    parser.add_argument('--interpolate',
                        help="--interpolate store_true , show interpolation on retries graph",
                        action="store_true")
    parser.add_argument('--duration',
                        help="--duration <seconds>",
                        default='20s')
    parser.add_argument('--polling_interval',
                        help="--polling_interval <h m s ms>",
                        default='1000ms')
    parser.add_argument('--frame',
                        help="--frame <bytes>  , e.g. --frame 1400",
                        default='1400')
    parser.add_argument('--frame_interval',
                        help="--frame_interval <fractions of second>  , e.g. --frame_interval .01 ",
                        default='.01')

    # Other Configuration
    parser.add_argument('--timeout_sec',
                        help="number of seconds to allow for starting traffic; if traffic has not started by this time, script will abort",
                        type=int,
                        default=30)
    parser.add_argument('--dhcp_poll_ms',
                        help="wait between checking vap probe results for new DHCP leases (milliseconds)",
                        type=int,
                        default=250)
    parser.add_argument('--dhcp_lookup_attempts',
                        help="number of attempts to check for DHCP lease before aborting script",
                        type=int,
                        default=20)

    return parser.parse_args()


def validate_args(args: argparse.Namespace):
    """
    Partial argument validation (some happens later on)

    :param args: Parsed arguments
    """
    # vAP radio required as full EID
    if not args.vap_radio.startswith("1."):
        logger.error("--vap_radio requires EID format: 1.1.wiphy0")
        exit(1)

    # vAP port required as full EID
    if not args.vap_port.startswith("1."):
        logger.error("--vap_port requires EID format: 1.1.vap0000")
        exit(1)

    # vAP mode must be one of available options
    #
    # Could limit this by using argparse choices, but that would also show unintuitive "p_802_11a"
    # option to user, somewhat confusing that it's 802.11a
    if args.vap_mode in ("a", "802.11a"):
        args.vap_mode = "p_802_11a"

    if args.vap_mode not in LFJsonCommand.AddVapMode.__members__:
        logger.error(f"Invalid mode \'{args.vap_mode}\'. Valid modes are: {LFJsonCommand.AddVapMode.__members__}")
        exit(1)

    # vAP TX power must be either DEFAULT or valid dBm value
    if args.vap_txpower != "DEFAULT":
        if not args.vap_txpower.endswith("dBm"):
            logger.error("vAP TX power must be either \'DEFAULT\' or an integer value in the format \'X dBm\', "
                         "where X is an integer between -1 and 30 inclusive")
            exit(1)

        txpower_int_str = args.vap_txpower.strip("dBm")
        if not txpower_int_str.isnumeric():
            logger.error("When not \'DEFAULT\', vAP TX power must be an integer value in the format \'X dBm\', "
                         "where X is an integer between -1 and 30 inclusive")
            exit(1)

        txpower_int = int(txpower_int_str)
        if not(-1 <= txpower_int and txpower_int <= 30):
            logger.error("vAP TX power must be either \'DEFAULT\' or an integer within range -1 to 30, inclusive")
            exit(1)


def configure_logger(log_level: str, logger_json_config: str = None):
    logger_config = lf_logger_config.lf_logger_config()

    if log_level:
        logger_config.set_level(level=log_level)

    # lf_logger_config_json will take presidence to changing debug levels
    if logger_json_config:
        logger_config.lf_logger_config_json = logger_json_config
        logger_config.load_lf_logger_config()


# TODO: Specify KPI CSV required args as parameters when implement KPI CSV generation.
#       Currently live in kwargs but are unused
def configure_reporting(no_html: bool,
                        no_pdf: bool,
                        local_lf_report_dir: str,
                        csv_outfile: str,
                        desc: str,
                        **kwargs):
    """
    Set up reporting data structures for later use.

    Do this before running the test to ensure required file permissions.

    NOTE: When running within the test framework (lf_check.py), results must be
    in the same directory.
    """
    logger.info("Configuring test reporting")

    html_file = "rf_char.html"
    if no_html:
        html_file = None

    pdf_file = "rf_char.pdf"
    if no_pdf:
        pdf_file = None

    if local_lf_report_dir != "":
        report = lf_report.lf_report(_path=local_lf_report_dir,
                                     _results_dir_name="rf_char",
                                     _output_html=html_file,
                                     _output_pdf=pdf_file)
    else:
        report = lf_report.lf_report(_results_dir_name="rf_characteristics_test",
                                     _output_html=html_file,
                                     _output_pdf=pdf_file)

    # Configure report header
    report.set_title("RF Characteristics Test")
    report.build_banner_left()
    report.start_content_div2()
    report.set_obj_html("Objective", "RF Characteristics Test: Report RX and TX characteristics")
    report.build_objective()

    if desc:
        report.set_desc_html("Test Description", desc)
        report.build_description()

    kpi_path = report.get_report_path()
    logger.info("Report and kpi_path :{kpi_path}".format(kpi_path=kpi_path))

    # Configure report CSV generation
    # TODO: Use KPI CSV?
    #kpi_csv = lf_kpi_csv.lf_kpi_csv(
    #    _kpi_path=kpi_path,
    #    _kpi_test_rig=test_rig,
    #    _kpi_test_tag=test_tag,
    #    _kpi_dut_hw_version=dut_hw_version,
    #    _kpi_dut_sw_version=dut_sw_version,
    #    _kpi_dut_model_num=dut_model_num,
    #    _kpi_dut_serial_num=dut_serial_num,
    #    _kpi_test_id=test_id)

    if csv_outfile is not None:
        current_time = time.strftime("%Y-%m-%d-%H-%M-%S", time.localtime())
        csv_outfile = "{}_{}_lf_rf_char.csv".format(
            csv_outfile, current_time)
        csv_outfile = report.file_add_path(csv_outfile)
        logger.info(f"Test CSV data will be output to file \'{csv_outfile}\'")
    else:
        logger.info(f"No CSV output file specified, disabling test CSV data output")

    return report


def generate_report(rf_char: RfCharTest,
                    json_wifi_stats: dict,
                    report,
                    generate_html: bool,
                    final_report_dir: str,
                    interpolate: bool,
                    polynomial: bool,
                    **kwargs):
    """Generate HTML and PDF reports after test completes."""
    # Get dataset for the radio
    if rf_char.vap_port not in json_wifi_stats:
        pprint(json_wifi_stats)
        raise ValueError("lf_rf_char: radio dataset for [%s] not found:" % rf_char.vap_port)

    wifi_stats_json = json_wifi_stats[rf_char.vap_port]
    if not wifi_stats_json:
        pprint(json_wifi_stats)
        raise ValueError("lf_rf_char: skipping empty wifi_stats_json:")

    if not wifi_stats_json:
        logger.error("unable to find json_wifi_stats[%s]: " % rf_char.vap_port)
        pprint(json_wifi_stats)
        raise ValueError("wifi_stats_json empty")

    # transmitted packets per polling interval
    tx_pkts = rf_char.tx_pkts
    tx_retries = rf_char.tx_retries
    tx_failed = rf_char.tx_failed
    tx_interval = rf_char.tx_interval
    tx_interval_time = rf_char.tx_interval_time

    # TX pkts, TX retries,  TX Failed %
    report.set_table_title("TX pkts , TX retries, TX Failed %")
    report.build_table_title()

    df_tx_info = pd.DataFrame({" Time Interval (s) ": [ti for ti in tx_interval],
                               " Time ": [k for k in tx_interval_time],
                               " TX Packets ": [i for i in tx_pkts],
                               " TX Retries ": [j for j in tx_retries],
                               " TX Failed % ": [m for m in tx_failed]})

    report.set_table_dataframe(df_tx_info)
    report.build_table()

    # Write out csv file
    report.set_csv_filename("tx_pkts_tx_retries_tx_failed.csv")
    report.write_dataframe_to_csv()

    # lf_bar_line_graph
    # failed %
    if generate_html:
        graph = lf_bar_line_graph(
            _data_set1=[tx_pkts, tx_retries],
            _data_set2=[tx_failed],
            _data_set2_poly=[polynomial],
            _data_set2_poly_degree=[3],
            _data_set2_interp1d=[interpolate],  # interpolate 1d
            _xaxis_name="Time Interval (s)",
            _y1axis_name="TX Packets",
            _y2axis_name="TX Failed %",
            _xaxis_categories=tx_interval,
            _graph_image_name="TX Info bar line",
            _label1=[" TX Packets ", " TX Retries "],
            _label2=[" TX Failed % "],
            _label2_poly=["% plynomial fit"],
            _label2_interp1d=[" % interpolate"],
            _color1=['blue', 'red'],
            _color2=['orange'],
            _color2_poly=['green'],
            _color2_interp1d=['cyan'],
            _marker=['o'],
            _color_edge='black',
            _figsize=(17, 7),
            _grp_title='TX ',
            _xaxis_step=1,
            _show_bar_value=True,
            _text_font=7,
            _text_rotation=45,
            _xticks_font=7,
            _legend_loc1="upper right",
            _legend_loc2="upper left",
            _legend_box1=(0, 0),
            _legend_box2=(1, 0),
            _legend_ncol=1,
            _legend_fontsize=None,
            _enable_csv=False)

        graph_png = graph.build_bar_line_graph()
        report.set_graph_image(graph_png)
        report.move_graph_image()
        report.build_graph()

    # RSSI line graphs
    rssi_signal = rf_char.rssi_signal
    rssi_1 = rf_char.rssi_1
    rssi_2 = rf_char.rssi_2
    rssi_3 = rf_char.rssi_3
    rssi_4 = rf_char.rssi_4
    tx_interval = rf_char.tx_interval
    data_set = [rssi_signal, rssi_1, rssi_2, rssi_3, rssi_4]
    label = ["RSSI Signal", "RSSI 1", "RSSI 2", "RSSI 3", "RSSI 4"]

    report.set_table_title("RSSI Signal, RSSI per chain")
    report.build_table_title()

    # TODO:  There is almost certainly a cleaner way to do this.
    data_set_debug = """inspect data sets for even distribution:
        tx_interval: {}
        tx_interval_time: {}
        rssi_signal: {} 
        rssi_1: {} 
        rssi_2: {} 
        rssi_3: {} 
        rssi_4: {}""".format(len(tx_interval),
                             len(tx_interval_time),
                             len(rssi_signal),
                             len(rssi_1),
                             len(rssi_2),
                             len(rssi_3),
                             len(rssi_4))
    df_rssi_info = None
    try:
        df_rssi_info = pd.DataFrame({" Time Interval (s)": [t for t in tx_interval],
                                     " Time ": [it for it in tx_interval_time],
                                     " RSSI Signal ": [k for k in rssi_signal],
                                     " RSSI 1 ": [i for i in rssi_1],
                                     " RSSI 2 ": [j for j in rssi_2],
                                     " RSSI 3 ": [m for m in rssi_3],
                                     " RSSI 4 ": [l for l in rssi_4]})
    except Exception as e:
        logger.error("Unable to build pandas DataFrame. Check for uneven data.")
        print(e)
        print (data_set_debug)
        sys.exit(1)

    report.set_table_dataframe(df_rssi_info.replace(np.nan, ''))
    report.build_table()

    report.set_csv_filename("rssi.csv")
    report.write_dataframe_to_csv()

    # graph RSSI
    if generate_html:
        graph = lf_line_graph(
            _data_set=data_set,
            _xaxis_name="Time Interval (s)",
            _yaxis_name="RSSI dBm",
            _reverse_y=False,
            _xaxis_categories=tx_interval,
            _graph_title="RSSI",
            _title_size=16,
            _graph_image_name="rssi",
            _label=label,
            _font_weight='bold',
            _color=['blue', 'orange', 'green', 'red', 'cyan'],
            _marker=["o" for _ in range(len(data_set))],
            _figsize=(17, 12),
            _xaxis_step=1,
            _text_font=7,
            _legend_loc="upper left",
            _legend_box=(1, 0),
            _legend_ncol=1
        )

        graph_png = graph.build_line_graph()
        report.set_graph_image(graph_png)
        report.move_graph_image()
        report.build_graph()

    # tx-rate / rx-rate negotiated rates line chart
    rx_rates : list[float] = []
    tx_rates : list[float] = []

    for index in range(0, min(len(rf_char.rx_rate), len(rf_char.tx_rate))):
        rx_str = rf_char.rx_rate[index]
        tx_str = rf_char.tx_rate[index]
        # print ("t:[{}] r:[{}] ".format(tx_str, rx_str))
        if "Mbps" in rx_str:
            rx_rates.append(float(rx_str[0 : rx_str.find(" ")]))
        else:
            rx_rates.append(0.0)

        if "Mbps" in tx_str:
            tx_rates.append(float(tx_str[0 : tx_str.find(" ")]))
        else:
            tx_rates.append(0.0)

    data_set = [tx_rates, rx_rates]
    label = ["TX-Rate", "RX-Rate"]
    report.set_table_title("Negotiated TX/RX-Rates")
    report.build_table_title()
    data_rates_frame = pd.DataFrame({" Time Interval (s)": [t for t in tx_interval],
                                     " Time ": [it for it in tx_interval_time],
                                     " TX-Rate ": [k for k in tx_rates],
                                     " RX-Rate ": [i for i in rx_rates]})
    report.set_table_dataframe(data_rates_frame)
    report.build_table()
    report.set_csv_filename("data-rates.csv")
    report.write_dataframe_to_csv()
    if generate_html:
        graph = lf_line_graph(
            _data_set=data_set,
            _xaxis_name="Time Interval (s)",
            _yaxis_name="Mbps",
            _reverse_y=False,
            _xaxis_categories=tx_interval,
            _graph_title="Negotiated TX/RX rates",
            _title_size=16,
            _graph_image_name="data-rates",
            _label=label,
            _font_weight='bold',
            _color=['blue', 'orange', 'green', 'red', 'cyan'],
            _figsize=(17, 12),
            _xaxis_step=1,
            _text_font=7,
            _legend_loc="upper left",
            _legend_box=(1, 0),
            _legend_ncol=1
        )
        graph_png = graph.build_line_graph()
        report.set_graph_image(graph_png)
        report.move_graph_image()
        report.build_graph()

    # retrieve rx data from json for MODE
    rx_mode = []
    rx_mode_value_str = []
    rx_mode_value = []
    rx_mode_value_percent = []
    rx_mode_total_count = 0

    # retrieve each mode value from json
    if not wifi_stats_json:
        raise ValueError("wifi_stats_json empty")
    for iterator in wifi_stats_json:
        if 'rx_mode' in iterator:
            rx_mode.append(iterator)
            rx_mode_value_str.append(str(wifi_stats_json[iterator]))
            rx_mode_value.append(wifi_stats_json[iterator])
            rx_mode_total_count += wifi_stats_json[iterator]

    if rx_mode_total_count == 0:
        logger.warning("Could not find any rx-mode packets.")
        logger.info(pformat(wifi_stats_json))
        # calculate percentages
        for rx_mode_count in rx_mode_value:
            rx_mode_value_percent.append(0)
    else:
        # calculate percentages
        for rx_mode_count in rx_mode_value:
            rx_mode_value_percent.append(round((rx_mode_count / rx_mode_total_count) * 100, 2))

    # manipulate data to sort by length to have
    # CCK is first, the OFDMA, then HT variants, then VHT, the HE
    rx_mode = [s.replace('v_rx_mode_ht', 'v_rx_mode_ht_AAA') for s in rx_mode]
    rx_mode = [s.replace('v_rx_mode_vht', 'v_rx_mode_vht_AAA') for s in rx_mode]
    rx_mode = [s.replace('v_rx_mode_he', 'v_rx_mode_he_AAA') for s in rx_mode]

    # rx_mode.sort(key=length_sort)
    logger.debug("Before sort rx mode: {rx_mode} : {rx_mode_value_str} : {rx_mode_value} : {rx_mode_value_percent}".
                 format(rx_mode=rx_mode, rx_mode_value_str=rx_mode_value_str, rx_mode_value=rx_mode_value, rx_mode_value_percent=rx_mode_value_percent))

    # see rx_mcs for details
    rx_mode, rx_mode_value_str, rx_mode_value, rx_mode_value_percent = map(list, zip(*sorted(zip(rx_mode, rx_mode_value_str, rx_mode_value, rx_mode_value_percent), key=length_sort)))

    logger.debug("After sort rx mode: {rx_mode} : {rx_mode_value_str} : {rx_mode_value} : {rx_mode_value_percent}".
                 format(rx_mode=rx_mode, rx_mode_value_str=rx_mode_value_str, rx_mode_value=rx_mode_value, rx_mode_value_percent=rx_mode_value_percent))

    rx_mode = [s.replace('v_rx_mode_', '') for s in rx_mode]
    rx_mode = [s.replace('AAA', '') for s in rx_mode]
    rx_mode = [s.replace('_', ' ') for s in rx_mode]
    rx_mode = [s.upper() for s in rx_mode]

    # rx_mode values
    report.set_table_title("RX Mode Histogram")
    report.build_table_title()

    df_rx_mode = pd.DataFrame({" RX Mode ": [k for k in rx_mode],
                               " Total Packets ": [i for i in rx_mode_value],
                               " Percentage ": [j for j in rx_mode_value_percent]})

    report.set_table_dataframe(df_rx_mode)
    report.build_table()

    report.set_csv_filename("rx_mode.csv")
    report.write_dataframe_to_csv()

    # RX MODE
    if generate_html:
        graph = lf_bar_graph(_data_set=[rx_mode_value_percent],
                             _xaxis_name="RX Mode",
                             _yaxis_name="Percent Packets RX per Mode",
                             _xaxis_categories=rx_mode,
                             _graph_image_name="RX Mode",
                             _label=["% Total Packets"],
                             _color=['blue'],
                             _color_edge='black',
                             _figsize=(18, 7),
                             _grp_title='RX Mode',
                             _xaxis_step=1,
                             _show_bar_value=True,
                             _text_font=7,
                             _text_rotation=45,
                             _xticks_font=7,
                             _legend_loc="best",
                             _legend_box=(1, 1),
                             _legend_ncol=1,
                             _legend_fontsize=None,
                             _enable_csv=False)

        graph_png = graph.build_bar_graph()
        report.set_graph_image(graph_png)
        report.move_graph_image()
        report.build_graph()

    # retrieve tx data from json for MODE
    tx_mode = []
    tx_mode_value_str = []
    tx_mode_value = []
    tx_mode_value_percent = []
    tx_mode_total_count = 0

    # TODO change value to count
    # retrieve each mode value from json
    for iterator in wifi_stats_json:
        if 'tx_mode' in iterator:
            tx_mode.append(iterator)
            tx_mode_value_str.append(str(wifi_stats_json[iterator]))
            tx_mode_value.append(wifi_stats_json[iterator])
            tx_mode_total_count += wifi_stats_json[iterator]

    if tx_mode_total_count == 0:
        logger.warning("Could not find any tx-mode packets.")
        logger.info(pformat(wifi_stats_json))
        # calculate percentages
        for tx_mode_count in tx_mode_value:
            tx_mode_value_percent.append(0)
    else:
        # calculate percentages
        for tx_mode_count in tx_mode_value:
            tx_mode_value_percent.append(round((tx_mode_count / tx_mode_total_count) * 100, 2))

    # manipulate data to sort by length to have
    # CCK is first, the OFDMA, then HT variants, then VHT, the HE
    tx_mode = [s.replace('v_tx_mode_ht', 'v_tx_mode_ht_AAA') for s in tx_mode]
    tx_mode = [s.replace('v_tx_mode_vht', 'v_tx_mode_vht_AAA') for s in tx_mode]
    tx_mode = [s.replace('v_tx_mode_he', 'v_tx_mode_he_AAA') for s in tx_mode]

    # tx_mode.sort(key=length_sort)
    logger.debug("Before sort: {tx_mode} : {tx_mode_value_str} : {tx_mode_value} : {tx_mode_value_percent}".
                 format(tx_mode=tx_mode,
                        tx_mode_value_str=tx_mode_value_str,
                        tx_mode_value=tx_mode_value,
                        tx_mode_value_percent=tx_mode_value_percent))

    # see rx_mcs for detales
    tx_mode, tx_mode_value_str, tx_mode_value, tx_mode_value_percent = map(list,
                                                                           zip(*sorted(zip(tx_mode, tx_mode_value_str,
                                                                                           tx_mode_value,
                                                                                           tx_mode_value_percent),
                                                                                       key=length_sort)))

    logger.debug("After sort: {tx_mode} : {tx_mode_value_str} : {tx_mode_value} : {tx_mode_value_percent}".
                 format(tx_mode=tx_mode,
                        tx_mode_value_str=tx_mode_value_str,
                        tx_mode_value=tx_mode_value,
                        tx_mode_value_percent=tx_mode_value_percent))

    tx_mode = [s.replace('v_tx_mode_', '') for s in tx_mode]
    tx_mode = [s.replace('AAA', '') for s in tx_mode]
    tx_mode = [s.replace('_', ' ') for s in tx_mode]
    tx_mode = [s.upper() for s in tx_mode]

    # tx_mode values
    report.set_table_title("TX Mode Histogram")
    report.build_table_title()

    df_tx_mode = pd.DataFrame({" TX Mode ": [k for k in tx_mode],
                               " Total Packets ": [i for i in tx_mode_value],
                               " Percentage ": [j for j in tx_mode_value_percent]})

    report.set_table_dataframe(df_tx_mode)
    report.build_table()

    report.set_csv_filename("tx_mode.csv")
    report.write_dataframe_to_csv()

    # TX MODE
    if generate_html:
        graph = lf_bar_graph(_data_set=[tx_mode_value_percent],
                             _xaxis_name="TX Mode",
                             _yaxis_name="Percent Packets TX per Mode",
                             _xaxis_categories=tx_mode,
                             _graph_image_name="TX Mode",
                             _label=["% Total Packets"],
                             _color=['blue'],
                             _color_edge='black',
                             _figsize=(17, 7),
                             _grp_title='TX Mode',
                             _xaxis_step=1,
                             _show_bar_value=True,
                             _text_font=7,
                             _text_rotation=45,
                             _xticks_font=7,
                             _legend_loc="best",
                             _legend_box=(1, 1),
                             _legend_ncol=1,
                             _legend_fontsize=None,
                             _enable_csv=False)

        graph_png = graph.build_bar_graph()
        report.set_graph_image(graph_png)
        report.move_graph_image()
        report.build_graph()

    # retrieve rx data from json for BW
    rx_bw = []
    rx_bw_value_str = []
    rx_bw_value = []
    rx_bw_value_percent = []
    rx_bw_total_count = 0

    # TODO change value to count
    # retrieve each nss value from json
    for iterator in wifi_stats_json:
        if 'rx_bw' in iterator:
            rx_bw.append(iterator)
            rx_bw_value_str.append(str(wifi_stats_json[iterator]))
            rx_bw_value.append(wifi_stats_json[iterator])
            rx_bw_total_count += wifi_stats_json[iterator]

    logger.debug("rx_bw: {rx_bw}".format(rx_bw=rx_bw))

    if rx_bw_total_count == 0:
        logger.warning("Could not find any rx-bw packets.")
        logger.info(pformat(wifi_stats_json))
        # calculate percentages
        for rx_bw_count in rx_bw_value:
            rx_bw_value_percent.append(0)
    else:
        # calculate percentages
        for rx_bw_count in rx_bw_value:
            rx_bw_value_percent.append(round((rx_bw_count / rx_bw_total_count) * 100, 2))

    logger.debug("Before sort rx bw: {rx_bw} : {rx_bw_value_str} : {rx_bw_value} : {rx_bw_value_percent}".
                 format(rx_bw=rx_bw,
                        rx_bw_value_str=rx_bw_value_str,
                        rx_bw_value=rx_bw_value,
                        rx_bw_value_percent=rx_bw_value_percent))

    # see rx_mcs for detales
    rx_bw, rx_bw_value_str, rx_bw_value, rx_bw_value_percent = map(list,
                                                                   zip(*sorted(zip(rx_bw, rx_bw_value_str, rx_bw_value,
                                                                                   rx_bw_value_percent), key=num_sort)))

    logger.debug("After sort rx bw: {rx_bw} : {rx_bw_value_str} : {rx_bw_value} : {rx_bw_value_percent}".
                 format(rx_bw=rx_bw,
                        rx_bw_value_str=rx_bw_value_str,
                        rx_bw_value=rx_bw_value,
                        rx_bw_value_percent=rx_bw_value_percent))

    # rx_bw.sort(key=num_sort)

    rx_bw = [s.replace('v_rx_bw_he_ru', 'HE RU') for s in rx_bw]

    rx_bw = [s.replace('v_rx_bw_', 'BW ') for s in rx_bw]

    # rx_bw values
    report.set_table_title("RX BW Histogram")
    report.build_table_title()

    df_rx_bw = pd.DataFrame({" RX BW ": [k for k in rx_bw], " Total Packets ": [i for i in rx_bw_value],
                             " Percentage ": [j for j in rx_bw_value_percent]})

    report.set_table_dataframe(df_rx_bw)
    report.build_table()

    report.set_csv_filename("rx_bw.csv")
    report.write_dataframe_to_csv()

    # RX BW
    if generate_html:
        graph = lf_bar_graph(_data_set=[rx_bw_value_percent],
                             _xaxis_name="RX BW",
                             _yaxis_name="Percent Packets RX per BW",
                             _xaxis_categories=rx_bw,
                             _graph_image_name="RX BW",
                             _label=["% Total Packets"],
                             _color=['blue'],
                             _color_edge='black',
                             _figsize=(17, 7),
                             _grp_title='RX BW',
                             _xaxis_step=1,
                             _show_bar_value=True,
                             _text_font=7,
                             _text_rotation=45,
                             _xticks_font=7,
                             _legend_loc="best",
                             _legend_box=(1, 1),
                             _legend_ncol=1,
                             _legend_fontsize=None,
                             _enable_csv=False)

        graph_png = graph.build_bar_graph()
        report.set_graph_image(graph_png)
        report.move_graph_image()
        report.build_graph()

    # retrieve tx data from json for BW
    tx_bw = []
    tx_bw_value_str = []
    tx_bw_value = []
    tx_bw_value_percent = []
    tx_bw_total_count = 0

    # TODO change value to count
    # retrieve each nss value from json
    for iterator in wifi_stats_json:
        if 'tx_bw' in iterator:
            tx_bw.append(iterator)
            tx_bw_value_str.append(str(wifi_stats_json[iterator]))
            tx_bw_value.append(wifi_stats_json[iterator])
            tx_bw_total_count += wifi_stats_json[iterator]
    if tx_bw_total_count == 0:
        logger.warning("Could not find any tx-bw packets.")
        logger.info(pformat(wifi_stats_json))
        # calculate percentages
        for tx_bw_count in tx_bw_value:
            tx_bw_value_percent.append(0)
    else:
        # calculate percentages
        for tx_bw_count in tx_bw_value:
            tx_bw_value_percent.append(round((tx_bw_count / tx_bw_total_count) * 100, 2))

    logger.debug("Before sort tx bw: {tx_bw} : {tx_bw_value_str} : {tx_bw_value} : {tx_bw_value_percent}".
                 format(tx_bw=tx_bw,
                        tx_bw_value_str=tx_bw_value_str,
                        tx_bw_value=tx_bw_value,
                        tx_bw_value_percent=tx_bw_value_percent))

    # see rx_mcs for detales
    tx_bw, tx_bw_value_str, tx_bw_value, tx_bw_value_percent = map(list,
                                                                   zip(*sorted(zip(tx_bw, tx_bw_value_str, tx_bw_value,
                                                                                   tx_bw_value_percent), key=num_sort)))

    logger.debug("After sort tx bw: {tx_bw} : {tx_bw_value_str} : {tx_bw_value} : {tx_bw_value_percent}".
                 format(tx_bw=tx_bw,
                        tx_bw_value_str=tx_bw_value_str,
                        tx_bw_value=tx_bw_value,
                        tx_bw_value_percent=tx_bw_value_percent))

    # tx_bw.sort(key=num_sort)

    tx_bw = [s.replace('v_tx_bw_', 'BW ') for s in tx_bw]

    # tx_bw values
    report.set_table_title("TX BW Histogram")
    report.build_table_title()

    df_tx_bw = pd.DataFrame({"TX BW": [k for k in tx_bw],
                             " Total Packets ": [i for i in tx_bw_value],
                             " Percentage ": [j for j in tx_bw_value_percent]})

    report.set_table_dataframe(df_tx_bw)
    report.build_table()

    report.set_csv_filename("tx_bw.csv")
    report.write_dataframe_to_csv()

    # TX BW
    if generate_html:
        graph = lf_bar_graph(_data_set=[tx_bw_value_percent],
                             _xaxis_name="TX BW",
                             _yaxis_name="Percent Packets TX per BW",
                             _xaxis_categories=tx_bw,
                             _graph_image_name="TX BW",
                             _label=["% Total Packets"],
                             _color=['blue'],
                             _color_edge='black',
                             _figsize=(17, 7),
                             _grp_title='TX BW',
                             _xaxis_step=1,
                             _show_bar_value=True,
                             _text_font=7,
                             _text_rotation=45,
                             _xticks_font=7,
                             _legend_loc="best",
                             _legend_box=(1, 1),
                             _legend_ncol=1,
                             _legend_fontsize=None,
                             _enable_csv=False)

        graph_png = graph.build_bar_graph()
        report.set_graph_image(graph_png)
        report.move_graph_image()
        report.build_graph()

    # retrieve rx data from json for NSS
    rx_nss = []
    rx_nss_value_str = []
    rx_nss_value = []
    rx_nss_value_percent = []
    rx_nss_total_count = 0

    # TODO change value to count
    # retrieve each nss value from json
    for iterator in wifi_stats_json:
        if 'rx_nss' in iterator:
            rx_nss.append(iterator)
            rx_nss_value_str.append(str(wifi_stats_json[iterator]))
            rx_nss_value.append(wifi_stats_json[iterator])
            rx_nss_total_count += wifi_stats_json[iterator]
    if rx_nss_total_count == 0:
        logger.warning("Could not find any rx-nss packets.")
        logger.info(pformat(wifi_stats_json))
        # calculate percentages
        for rx_nss_count in rx_nss_value:
            rx_nss_value_percent.append(0)
    else:
        # calculate percentages
        for rx_nss_count in rx_nss_value:
            rx_nss_value_percent.append(round((rx_nss_count / rx_nss_total_count) * 100, 2))

    rx_nss = [s.replace('v_rx_nss_1', '1 x 1') for s in rx_nss]
    rx_nss = [s.replace('v_rx_nss_2', '2 x 2') for s in rx_nss]
    rx_nss = [s.replace('v_rx_nss_3', '3 x 3') for s in rx_nss]
    rx_nss = [s.replace('v_rx_nss_4', '4 x 4') for s in rx_nss]

    # rx_nss values
    report.set_table_title("RX NSS Histogram")
    report.build_table_title()

    df_rx_nss = pd.DataFrame({" RX NSS ": [k for k in rx_nss],
                              " Total Packets ": [i for i in rx_nss_value],
                              " Percentage ": [j for j in rx_nss_value_percent]})

    report.set_table_dataframe(df_rx_nss)
    report.build_table()

    report.set_csv_filename("rx_nss.csv")
    report.write_dataframe_to_csv()

    # RX NSS
    if generate_html:
        graph = lf_bar_graph(_data_set=[rx_nss_value_percent],
                             _xaxis_name="RX NSS",
                             _yaxis_name="Percent RX Packets of NSS",
                             _xaxis_categories=rx_nss,
                             _graph_image_name="RX NSS",
                             _label=["% Total Packets"],
                             _color=['blue'],
                             _color_edge='black',
                             _figsize=(17, 7),
                             _grp_title='RX NSS',
                             _xaxis_step=1,
                             _show_bar_value=True,
                             _text_font=7,
                             _text_rotation=45,
                             _xticks_font=7,
                             _legend_loc="best",
                             _legend_box=(1, 1),
                             _legend_ncol=1,
                             _legend_fontsize=None,
                             _enable_csv=False)

        graph_png = graph.build_bar_graph()
        report.set_graph_image(graph_png)
        report.move_graph_image()
        report.build_graph()

    # retrieve tx data from json for NSS
    tx_nss = []
    tx_nss_value_str = []
    tx_nss_value = []
    tx_nss_value_percent = []
    tx_nss_total_count = 0

    # TODO change value to count
    # retrieve each nss value from json
    for iterator in wifi_stats_json:
        if 'tx_nss' in iterator:
            tx_nss.append(iterator)
            tx_nss_value_str.append(str(wifi_stats_json[iterator]))
            tx_nss_value.append(wifi_stats_json[iterator])
            tx_nss_total_count += wifi_stats_json[iterator]
    if tx_nss_total_count == 0:
        logger.warning("Could not find any tx-nss packets.")
        logger.info(pformat(wifi_stats_json))
        # calculate percentages
        for tx_nss_count in tx_nss_value:
            tx_nss_value_percent.append(0)
    else:
        # calculate percentages
        for tx_nss_count in tx_nss_value:
            tx_nss_value_percent.append(round((tx_nss_count / tx_nss_total_count) * 100, 2))

    tx_nss = [s.replace('v_tx_nss_1', '1 x 1') for s in tx_nss]
    tx_nss = [s.replace('v_tx_nss_2', '2 x 2') for s in tx_nss]
    tx_nss = [s.replace('v_tx_nss_3', '3 x 3') for s in tx_nss]
    tx_nss = [s.replace('v_tx_nss_4', '4 x 4') for s in tx_nss]

    # tx_nss values
    report.set_table_title("TX NSS Histogram")
    report.build_table_title()

    df_tx_nss = pd.DataFrame({" TX NSS ": [k for k in tx_nss],
                              " Total Packets ": [i for i in tx_nss_value],
                              " Percentage ": [j for j in tx_nss_value_percent]})

    report.set_table_dataframe(df_tx_nss)
    report.build_table()

    report.set_csv_filename("tx_nss.csv")
    report.write_dataframe_to_csv()

    # TX NSS
    if generate_html:
        graph = lf_bar_graph(_data_set=[tx_nss_value_percent],
                             _xaxis_name="TX NSS",
                             _yaxis_name="Percent TX Packets of NSS",
                             _xaxis_categories=tx_nss,
                             _graph_image_name="TX NSS",
                             _label=["% Total Packets"],
                             _color=['blue'],
                             _color_edge='black',
                             _figsize=(17, 7),
                             _grp_title='TX NSS',
                             _xaxis_step=1,
                             _show_bar_value=True,
                             _text_font=7,
                             _text_rotation=45,
                             _xticks_font=7,
                             _legend_loc="best",
                             _legend_box=(1, 1),
                             _legend_ncol=1,
                             _legend_fontsize=None,
                             _enable_csv=False)

        graph_png = graph.build_bar_graph()
        report.set_graph_image(graph_png)
        report.move_graph_image()
        report.build_graph()

    # retrieve rx data from json for MCS
    rx_mcs = []
    rx_mcs_value_str = []
    rx_mcs_value = []
    rx_mcs_value_percent = []
    rx_mcs_total_count = 0

    # TODO change value to count
    # retrieve each mcs value from json
    for iterator in wifi_stats_json:
        if 'rx_mcs' in iterator:
            rx_mcs.append(iterator)
            rx_mcs_value_str.append(str(wifi_stats_json[iterator]))
            rx_mcs_value.append(wifi_stats_json[iterator])
            rx_mcs_total_count += wifi_stats_json[iterator]

    if rx_mcs_total_count == 0:
        logger.warning("Could not find any rx-mode packets.")
        logger.info(pformat(wifi_stats_json))
        # calculate percentages
        for rx_mcs_count in rx_mcs_value:
            rx_mcs_value_percent.append(0)
    else:
        # calculate percentages
        for rx_mcs_count in rx_mcs_value:
            rx_mcs_value_percent.append(round((rx_mcs_count / rx_mcs_total_count) * 100, 2))

    logger.info("Before sort rx MCS {rx_mcs} : {rx_mcs_value_str} : {rx_mcs_value} : {rx_mcs_value_percent}".
                format(rx_mcs=rx_mcs,
                       rx_mcs_value_str=rx_mcs_value_str,
                       rx_mcs_value=rx_mcs_value,
                       rx_mcs_value_percent=rx_mcs_value_percent))

    #
    zip_rx_mcs = zip(rx_mcs, rx_mcs_value_str, rx_mcs_value, rx_mcs_value_percent)

    # https://stackoverflow.com/questions/19931975/sort-multiple-lists-simultaneously
    # https://www.geeksforgeeks.org/sorted-function-python/
    # use the rx_mcs as the sort key
    # Using the tuples default ordering
    zip_rx_mcs_sort = sorted(zip_rx_mcs, key=num_sort)

    # https://www.geeksforgeeks.org/python-unzip-a-list-of-tuples/
    res_mcs = zip(*zip_rx_mcs_sort)

    # return the sorted lists
    rx_mcs, rx_mcs_value_str, rx_mcs_value, rx_mcs_value_percent = map(list, res_mcs)

    logger.info("After sort rx MCS {rx_mcs} : {rx_mcs_value_str} : {rx_mcs_value} : {rx_mcs_value_percent}".
                format(rx_mcs=rx_mcs,
                       rx_mcs_value_str=rx_mcs_value_str,
                       rx_mcs_value=rx_mcs_value,
                       rx_mcs_value_percent=rx_mcs_value_percent))

    rx_mcs = [s.replace('v_rx_mcs_', 'MCS ') for s in rx_mcs]

    # the above could be done with this one command
    # rx_mcs, rx_mcs_value_str, rx_mcs_value = map(list, zip(*sorted(zip(rx_mcs,rx_mcs_value_str,rx_mcs_value),key=num_sort)))

    # rx_mcs values
    report.set_table_title("RX MCS Histogram")
    report.build_table_title()

    df_rx_mcs = pd.DataFrame({" RX MCS ": [k for k in rx_mcs],
                              " Total Packets ": [i for i in rx_mcs_value],
                              " Percentage ": [j for j in rx_mcs_value_percent]})

    report.set_table_dataframe(df_rx_mcs)
    report.build_table()

    report.set_csv_filename("rx_mcs.csv")
    report.write_dataframe_to_csv()

    # RX MCS encoding
    if generate_html:
        graph = lf_bar_graph(_data_set=[rx_mcs_value_percent],
                             _xaxis_name="RX MCS encoding",
                             _yaxis_name="Percent RX Packets per MCS encoding",
                             _xaxis_categories=rx_mcs,
                             _graph_image_name="RX MCS encoding",
                             _label=["% Total Packets"],
                             _color=['blue'],
                             _color_edge='black',
                             _figsize=(17, 7),
                             _grp_title='RX MCS encoding',
                             _xaxis_step=1,
                             _show_bar_value=True,
                             _text_font=7,
                             _text_rotation=45,
                             _xticks_font=7,
                             _legend_loc="best",
                             _legend_box=(1, 1),
                             _legend_ncol=1,
                             _legend_fontsize=None,
                             _enable_csv=False)

        graph_png = graph.build_bar_graph()
        report.set_graph_image(graph_png)
        report.move_graph_image()
        report.build_graph()

    # retrieve tx  mcs value from json
    tx_mcs = []
    tx_mcs_value_str = []
    tx_mcs_value = []
    tx_mcs_value_percent = []
    tx_mcs_total_count = 0

    for iterator in wifi_stats_json:
        if 'tx_mcs' in iterator:
            tx_mcs.append(iterator)
            tx_mcs_value_str.append(str(wifi_stats_json[iterator]))
            tx_mcs_value.append(wifi_stats_json[iterator])
            tx_mcs_total_count += wifi_stats_json[iterator]

    # calculate percentages
    for tx_mcs_count in tx_mcs_value:
        if tx_mcs_total_count == 0:
            tx_mcs_value_percent.append(0)
        else:
            tx_mcs_value_percent.append(round((tx_mcs_count / tx_mcs_total_count) * 100, 2))

    logger.debug("Before sort tx MCS: {tx_mcs} : {tx_mcs_value_str} : {tx_mcs_value} : {tx_mcs_value_percent}".
                 format(tx_mcs=tx_mcs,
                        tx_mcs_value_str=tx_mcs_value_str,
                        tx_mcs_value=tx_mcs_value,
                        tx_mcs_value_percent=tx_mcs_value_percent))

    # see rx_mcs for details
    tx_mcs, tx_mcs_value_str, tx_mcs_value, tx_mcs_value_percent = map(list,
                                                                       zip(*sorted(
                                                                           zip(tx_mcs, tx_mcs_value_str, tx_mcs_value,
                                                                               tx_mcs_value_percent), key=num_sort)))

    logger.debug("After sort tx MCS: {tx_mcs} : {tx_mcs_value_str} : {tx_mcs_value} : {tx_mcs_value_percent}".
                 format(tx_mcs=tx_mcs,
                        tx_mcs_value_str=tx_mcs_value_str,
                        tx_mcs_value=tx_mcs_value,
                        tx_mcs_value_percent=tx_mcs_value_percent))

    # tx_mcs.sort(key=num_sort)

    tx_mcs = [s.replace('v_tx_mcs_', 'MCS ') for s in tx_mcs]

    # tx_mcs values
    report.set_table_title("TX MCS Histogram")
    report.build_table_title()

    df_tx_mcs = pd.DataFrame({" TX MCS ": [k for k in tx_mcs],
                              " Total Packets ": [i for i in tx_mcs_value],
                              " Percentage ": [j for j in tx_mcs_value_percent]})

    report.set_table_dataframe(df_tx_mcs)
    report.build_table()

    report.set_csv_filename("tx_mcs.csv")
    report.write_dataframe_to_csv()

    # TX MCS encoding
    if generate_html:
        graph = lf_bar_graph(_data_set=[tx_mcs_value_percent],
                             _xaxis_name="TX MCS encoding",
                             _yaxis_name="Percentage Received Packets with MCS encoding",
                             _xaxis_categories=tx_mcs,
                             _graph_image_name="TX MCS encoding",
                             _label=["% Total Packets"],
                             _color=['blue'],
                             _color_edge='black',
                             _figsize=(17, 7),
                             _grp_title='TX MCS encoding',
                             _xaxis_step=1,
                             _show_bar_value=True,
                             _text_font=7,
                             _text_rotation=45,
                             _xticks_font=7,
                             _legend_loc="best",
                             _legend_box=(1, 1),
                             _legend_ncol=1,
                             _legend_fontsize=None,
                             _enable_csv=False)

        graph_png = graph.build_bar_graph()
        report.set_graph_image(graph_png)
        report.move_graph_image()
        report.build_graph()

    # retrieve rx data from json for ampdu
    rx_ampdu = []
    rx_ampdu_value_str = []
    rx_ampdu_value = []
    rx_ampdu_value_percent = []
    rx_ampdu_total_count = 0

    # TODO change value to count
    # retrieve each mcs value from json
    for iterator in wifi_stats_json:
        if 'rx_ampdu' in iterator:
            rx_ampdu.append(iterator)
            rx_ampdu_value_str.append(str(wifi_stats_json[iterator]))
            rx_ampdu_value.append(wifi_stats_json[iterator])
            rx_ampdu_total_count += wifi_stats_json[iterator]

    logger.debug("rx_ampdu: {rx_ampdu}".format(rx_ampdu=rx_ampdu))

    logger.debug("Before sort rx AMPDU: {rx_ampdu} : {rx_ampdu_value_str} : {rx_ampdu_value}".
                 format(rx_ampdu=rx_ampdu, rx_ampdu_value_str=rx_ampdu_value_str, rx_ampdu_value=rx_ampdu_value))

    # see rx_mcs for detales
    rx_ampdu, rx_ampdu_value_str, rx_ampdu_value = map(list,
                                                       zip(*sorted(zip(rx_ampdu, rx_ampdu_value_str, rx_ampdu_value),
                                                                   key=num_sort)))

    logger.debug("After sort rx AMPDU: {rx_ampdu} : {rx_ampdu_value_str} : {rx_ampdu_value}".
                 format(rx_ampdu=rx_ampdu,
                        rx_ampdu_value_str=rx_ampdu_value_str,
                        rx_ampdu_value=rx_ampdu_value))

    # rx_ampdu.sort(key=num_sort)

    rx_ampdu = [s.replace('rx_ampdu_len_', '') for s in rx_ampdu]
    rx_ampdu = [s.replace('_', '-') for s in rx_ampdu]

    logger.debug("rx_ampdu: {rx_ampdu}".format(rx_ampdu=rx_ampdu))

    # use class

    # calculate percentages
    for rx_ampdu_count in rx_ampdu_value:
        if rx_ampdu_total_count == 0:
            rx_ampdu_value_percent.append(0)
        else:
            rx_ampdu_value_percent.append(round((rx_ampdu_count / rx_ampdu_total_count) * 100, 2))

    # rx_ampdu values
    report.set_table_title("Packets RX with AMPDU Count")
    report.build_table_title()

    df_rx_ampdu = pd.DataFrame({" RX AMPDU ": [k for k in rx_ampdu],
                                " Total Packets ": [i for i in rx_ampdu_value],
                                " Percentage ": [j for j in rx_ampdu_value_percent]})

    report.set_table_dataframe(df_rx_ampdu)
    report.build_table()

    report.set_csv_filename("rx_ampdu.csv")
    report.write_dataframe_to_csv()

    # RX ampdu encoding
    if generate_html:
        graph = lf_bar_graph(_data_set=[rx_ampdu_value_percent],
                             _xaxis_name="RX ampdu",
                             _yaxis_name="Percent Packets RX with AMPDU Count",
                             _xaxis_categories=rx_ampdu,
                             _graph_image_name="RX AMPDU Count",
                             _label=["% Total Packets"],
                             _color=['blue'],
                             _color_edge='black',
                             _figsize=(17, 7),
                             _grp_title='RX ampdu',
                             _xaxis_step=1,
                             _show_bar_value=True,
                             _text_font=7,
                             _text_rotation=45,
                             _xticks_font=7,
                             _legend_loc="best",
                             _legend_box=(1, 1),
                             _legend_ncol=1,
                             _legend_fontsize=None,
                             _enable_csv=False)

        graph_png = graph.build_bar_graph()
        report.set_graph_image(graph_png)
        report.move_graph_image()
        report.build_graph()

    # retrieve tx ampdu value from json
    tx_ampdu = []
    tx_ampdu_value_str = []
    tx_ampdu_value = []
    tx_ampdu_value_percent = []
    tx_ampdu_total_count = 0

    for iterator in wifi_stats_json:
        if 'tx_ampdu' in iterator:
            tx_ampdu.append(iterator)
            tx_ampdu_value_str.append(str(wifi_stats_json[iterator]))
            tx_ampdu_value.append(wifi_stats_json[iterator])
            tx_ampdu_total_count += wifi_stats_json[iterator]

    # calculate percentages
    for tx_ampdu_count in tx_ampdu_value:
        if tx_ampdu_total_count == 0:
            tx_ampdu_value_percent.append(0)
        else:
            tx_ampdu_value_percent.append(round((tx_ampdu_count / tx_ampdu_total_count) * 100, 2))

    logger.debug(tx_ampdu)

    logger.debug("Before sort tx AMPDU: {tx_ampdu} : {tx_ampdu_value_str} : {tx_ampdu_value}".
                 format(tx_ampdu=tx_ampdu,
                        tx_ampdu_value_str=tx_ampdu_value_str,
                        tx_ampdu_value=tx_ampdu_value))

    # see rx_mcs for detales
    tx_ampdu, tx_ampdu_value_str, tx_ampdu_value = map(list,
                                                       zip(*sorted(zip(tx_ampdu, tx_ampdu_value_str, tx_ampdu_value),
                                                                   key=num_sort)))

    logger.debug("After sort tx AMPDU: {tx_ampdu} : {tx_ampdu_value_str} : {tx_ampdu_value}".
                 format(tx_ampdu=tx_ampdu,
                        tx_ampdu_value_str=tx_ampdu_value_str,
                        tx_ampdu_value=tx_ampdu_value))

    # tx_ampdu.sort(key=num_sort)
    tx_ampdu = [s.replace('tx_ampdu_len_', '') for s in tx_ampdu]
    tx_ampdu = [s.replace('_', '-') for s in tx_ampdu]

    logger.debug("tx_ampdu: {tx_ampdu}".format(tx_ampdu=tx_ampdu))

    # tx_ampdu values
    report.set_table_title("Percent Packets TX with AMPDU Count")
    report.build_table_title()

    df_tx_ampdu = pd.DataFrame({" TX AMPDU ": [k for k in tx_ampdu],
                                " Total Packets ": [i for i in tx_ampdu_value],
                                " Percentage ": [j for j in tx_ampdu_value_percent]})

    report.set_table_dataframe(df_tx_ampdu)
    report.build_table()

    report.set_csv_filename("tx_ampdu.csv")
    report.write_dataframe_to_csv()

    # TX ampdu
    if generate_html:
        graph = lf_bar_graph(_data_set=[tx_ampdu_value_percent],
                             _xaxis_name="TX ampdu",
                             _yaxis_name="Percent Packets TX with AMPDU Count",
                             _xaxis_categories=tx_ampdu,
                             _graph_image_name="TX ampdu encoding",
                             _label=["% Total Packets"],
                             _color=['blue'],
                             _color_edge='black',
                             _figsize=(17, 7),
                             _grp_title='TX ampdu',
                             _xaxis_step=1,
                             _show_bar_value=True,
                             _text_font=7,
                             _text_rotation=45,
                             _xticks_font=7,
                             _legend_loc="best",
                             _legend_box=(1, 1),
                             _legend_ncol=1,
                             _legend_fontsize=None,
                             _enable_csv=False)

        graph_png = graph.build_bar_graph()
        report.set_graph_image(graph_png)
        report.move_graph_image()
        report.build_graph()

    # retrieve tx msdu value from json
    tx_msdu = []
    tx_msdu_value_str = []
    tx_msdu_value = []
    tx_msdu_value_percent = []
    tx_msdu_total_count = 0

    for iterator in wifi_stats_json:
        if 'tx_msdu' in iterator:
            tx_msdu.append(iterator)
            tx_msdu_value_str.append(str(wifi_stats_json[iterator]))
            tx_msdu_value.append(wifi_stats_json[iterator])
            tx_msdu_total_count += wifi_stats_json[iterator]

    # calculate percentages
    for tx_msdu_count in tx_msdu_value:
        if tx_msdu_total_count == 0:
            tx_msdu_value_percent.append(0)
        else:
            tx_msdu_value_percent.append(round((tx_msdu_count / tx_msdu_total_count) * 100, 2))

    tx_msdu = [s.replace('tx_msdu_pack_', '') for s in tx_msdu]

    # tx_msdu values
    report.set_table_title("TX MSDU Histogram")
    report.build_table_title()

    df_tx_msdu = pd.DataFrame({" TX MSDU ": [k for k in tx_msdu],
                               " Total Packets ": [i for i in tx_msdu_value],
                               " Percentage ": [j for j in tx_msdu_value_percent]})

    report.set_table_dataframe(df_tx_msdu)
    report.build_table()

    report.set_csv_filename("tx_msdu.csv")
    report.write_dataframe_to_csv()

    # TX msdu
    if generate_html:
        graph = lf_bar_graph(_data_set=[tx_msdu_value_percent],
                             _xaxis_name="TX MSDU",
                             _yaxis_name="Percent Packets TX per MSDU",
                             _xaxis_categories=tx_msdu,
                             _graph_image_name="TX MSDU",
                             _label=["% Total Packets"],
                             _color=['blue'],
                             _color_edge='black',
                             _figsize=(17, 7),
                             _grp_title='TX msdu',
                             _xaxis_step=1,
                             _show_bar_value=True,
                             _text_font=7,
                             _text_rotation=45,
                             _xticks_font=7,
                             _legend_loc="best",
                             _legend_box=(1, 1),
                             _legend_ncol=1,
                             _legend_fontsize=None,
                             _enable_csv=False)

        graph_png = graph.build_bar_graph()
        report.set_graph_image(graph_png)
        report.move_graph_image()
        report.build_graph()

    # Finish the report
    report.build_footer()
    report.copy_js()

    if report.output_html.lower().endswith(".pdf"):
        raise ValueError("this report is misconfigured, HTML files should not have PDF suffixes")

    report.write_html_with_timestamp()
    report.write_index_html()

    if platform.system() == 'Linux':
        report.write_pdf_with_timestamp(_page_size='A4', _orientation='Landscape')

    if final_report_dir:
        if final_report_dir[0] == "/":
            logger.info("moving the report directory to " + final_report_dir)
            os.rename(report.get_report_path(), final_report_dir)
        else:
            logger.info("final dir: /home/lanforge/html-reports/" + final_report_dir)
            os.rename(report.get_report_path(),
                      "/home/lanforge/html-reports/" + final_report_dir)


def main():
    args = parse_args()
    configure_logger(log_level=args.log_level,
                     logger_json_config=args.lf_logger_config_json)
    validate_args(args)

    report = configure_reporting(**vars(args))

    # Set up the RF Characteristic test
    logger.info("Configuring test")
    rf_char = RfCharTest(**vars(args))

    logger.info("Performing pre-test cleanup")
    rf_char.remove_generic_cx()

    # Clear active vAP DHCP leases and identify latest event
    rf_char.clear_dhcp_lease()
    rf_char.bookmark_events()

    # Configure vAP, sleep to ensure properly configured
    rf_char.configure_vap()
    time.sleep(1)

    # Reset any existing station DHCP leases
    deadline_millis = now_millis() + (args.timeout_sec * 1000)
    rf_char.verify_dut_stations(deadline_millis=deadline_millis,
                                dhcp_lookup_ms=args.dhcp_poll_ms,
                                max_dhcp_lookups=args.dhcp_lookup_attempts)

    dut_mac = rf_char.dut_mac
    dut_ip = rf_char.dut_ip

    test_setup_info = {
        "DUT Name": rf_char.dut_hostname,
        "DUT Model": args.dut_model_num,
        "DUT Hardware Version": args.dut_hw_version,
        "DUT Software Version": args.dut_sw_version,
        "DUT Serial Number": args.dut_serial_num,
        "DUT MAC": dut_mac,
        "DUT IP": dut_ip
    }

    report.set_table_title("Device Under Test Information")
    report.build_table_title()
    report.test_setup_table(value="Device Under Test", test_setup_data=test_setup_info)

    # Set the report timer
    # use the duration in seconds to set the report timer
    # TODO call only once
    polling_interval_milliseconds = rf_char.duration_time_to_milliseconds(args.polling_interval)
    # polling_interval_milliseconds = polling_interval_seconds*1000
    rf_char.set_port_report_timer(port=args.vap_port, milliseconds=polling_interval_milliseconds)
    rf_char.set_port_report_timer(port=args.vap_radio, milliseconds=polling_interval_milliseconds)

    # Enable additional vAP parent radio settings to get more statistics
    flags_list = ['extra_rxstatus', 'extra_txstatus']
    rf_char.set_wifi_radio(flags_list=flags_list)

    if now_millis() > deadline_millis:
        raise ValueError("Time expired to start traffic")

    test_input_info = {
        "LANforge ip": args.lf_mgr,
        "LANforge port": args.lf_port,
        "Test Duration": args.duration,
        "Polling Interval": args.polling_interval,
        "GUI Report Interval (ms) vap and vap radio": str(polling_interval_milliseconds),
        "vAP Channel": args.vap_channel,
        "vAP Mode:": args.vap_mode,
        "vAP Bandwidth:": args.vap_bw,
        "vAP TX Power (dBm):": "Requested: {}<br/>\nApplied: {}".format(args.vap_txpower, rf_char.vap_txpower)
    }

    report.set_table_title("Test Configuration")
    report.build_table_title()
    report.test_setup_table(value="Test Configuration", test_setup_data=test_input_info)

    if now_millis() > deadline_millis:
        raise ValueError("Time expired to start traffic")

    rf_char.clear_port_counters()

    if now_millis() > deadline_millis:
        raise ValueError("Time expired to start traffic")
    begin_traffic_ms = now_millis()

    # Run the test
    logger.info("Beginning test")
    json_port_stats, json_wifi_stats, *nil = rf_char.start()
    time_elapsed = float((now_millis() - begin_traffic_ms) / 1000)
    logger.info(f"Traffic time took {time_elapsed} seconds")

    # Test complete, begin building report
    logger.info("Building test report")
    generate_report(rf_char=rf_char,
                    json_wifi_stats=json_wifi_stats,
                    report=report,
                    generate_html=(not args.no_html),
                    **vars(args))

    # remove previous generic endpoints
    rf_char.remove_generic_cx()


if __name__ == "__main__":
    main()
